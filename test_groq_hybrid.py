#!/usr/bin/env python3
"""
GROQ API + KNOWLEDGE BASE HYBRID SYSTEM
Use Groq API for general questions and knowledge base for specific topics
"""

import sys
sys.path.insert(0, 'ai_avatar_chatbot')

import os
import requests
import json
import logging
from typing import Dict, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GroqKnowledgeBaseHybrid:
    """
    Hybrid system using Groq API for general questions and knowledge base for specific topics
    """
    
    def __init__(self):
        # Load environment variables
        self.load_environment()
        
        # Groq API configuration
        self.groq_api_key = os.getenv("GROQ_API_KEY", "")
        self.base_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = "llama-3.1-8b-instant"
        self.timeout = 30
        
        # Check if Groq API is available
        if not self.groq_api_key or not self.groq_api_key.startswith("gsk_"):
            logger.warning("Groq API key not found. Using fallback responses.")
            self.is_groq_available = False
        else:
            self.is_groq_available = True
            logger.info("Groq API integration initialized successfully")
        
        # Knowledge base topics (use knowledge base for these)
        self.knowledge_base_topics = [
            'lms', 'learning management system', 'athena lms', 'course management',
            'subscription', 'billing', 'payment', 'cancel', 'renewal',
            'courses', 'access', 'enrollment', 'dashboard',
            'creditor academy', 'academy', 'member', 'support',
            'technical', 'login', 'password', 'account', 'settings'
        ]
        
        # General knowledge topics (use Groq API for these)
        self.general_knowledge_topics = [
            'what is', 'explain', 'how to', 'why', 'when', 'where',
            'compare', 'vs', 'best', 'how should', 'can i',
            'artificial intelligence', 'machine learning', 'python', 'javascript',
            'investment', 'finance', 'business', 'technology', 'science',
            'history', 'education', 'learning', 'help'
        ]
        
        # Initialize Groq API integration
        self.groq_integration = GroqAPIIntegration()
    
    def load_environment(self):
        """Load environment variables from .env file"""
        try:
            with open('.env', 'r') as f:
                for line in f:
                    if line.strip() and '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        os.environ[key.strip()] = value.strip()
        except Exception as e:
            logger.error(f"Error loading .env file: {e}")
    
    def classify_question_type(self, question: str) -> str:
        """
        Classify question type: KB (knowledge base) or General (Groq API)
        """
        question_lower = question.lower().strip()
        
        # Check if it's a knowledge base topic
        for topic in self.knowledge_base_topics:
            if topic in question_lower:
                return 'knowledge_base'
        
        # Check if it's a general knowledge topic
        for topic in self.general_knowledge_topics:
            if topic in question_lower:
                return 'general_knowledge'
        
        # Default to general knowledge
        return 'general_knowledge'
    
    def generate_response(self, question: str, context: str = None, llm_instance = None) -> Dict:
        """
        Generate response using appropriate method
        """
        
        question_type = self.classify_question_type(question)
        
        if question_type == 'knowledge_base':
            # Use knowledge base for KB topics
            return self._generate_kb_response(question, context)
        
        elif question_type == 'general_knowledge':
            # Use Groq API for general knowledge
            return self.groq_integration.generate_response_with_groq(question, context)
        
        else:
            # Fallback
            return self._generate_fallback_response(question)
    
    def _generate_kb_response(self, question: str, context: str) -> Dict:
        """Generate response using knowledge base"""
        
        # Try to get context from knowledge base
        if context and llm_instance:
            try:
                context_result = llm_instance.generate_response(
                    f"""You are a helpful AI assistant answering using the knowledge base.

KNOWLEDGE BASE:
{context}

QUESTION: {question}

ANSWER:""",
                    temperature=0.3
                )
                return {
                    'response': context_result,
                    'method': 'knowledge_base',
                    'confidence': 0.85,
                    'source': 'knowledge_base',
                    'context_used': True
                }
            except Exception as e:
                logger.error(f"KB generation failed: {e}")
                return self._generate_fallback_response(question)
        
        # Fallback to answer database
        return self._generate_fallback_response(question)
    
    def _generate_fallback_response(self, question: str) -> Dict:
        """Generate fallback response"""
        
        question_lower = question.lower().strip()
        
        # Check for exact matches in our database
        if question_lower in self.accurate_answers:
            return {
                'response': self.accurate_answers[question_lower],
                'method': 'exact_match',
                'confidence': 0.95,
                'source': 'database',
                'context_used': False
            }
        
        # Check for partial matches
        for key, answer in self.accurate_answers.items():
            if key in question_lower or question_lower in key:
                return {
                    'response': answer,
                    'method': 'partial_match',
                    'confidence': 0.85,
                    'source': 'database',
                    'context_used': False
                }
        
        # Generate contextual response
        if 'lms' in question_lower:
            return {
                'response': "LMS (Learning Management System) is a software platform designed to create, manage, and deliver online educational courses and training programs. It provides tools for course creation, student enrollment, progress tracking, assessments, and communication. You can access your courses through the dashboard once enrolled.",
                'method': 'contextual',
                'confidence': 0.75,
                'source': 'contextual_generation',
                'context_used': False
            }
        
        elif 'subscription' in question_lower or 'cancel' in question_lower:
            return {
                'response': "To cancel your subscription: 1) Log into your account, 2) Go to Account Settings, 3) Click on Subscription, 4) Select Cancel Membership, 5) Confirm cancellation. You'll retain access until your current billing period ends.",
                'method': 'contextual',
                'confidence': 0.75,
                'source': 'contextual_generation',
                'context_used': False
            }
        
        elif 'course' in question_lower or 'access' in question_lower:
            return {
                'response': "To access your courses: 1) Log into your account, 2) Click Dashboard or My Courses, 3) Select your course, 4) Click to access course materials. If you need help, contact support@creditoracademy.com.",
                'method': 'contextual',
                'confidence': 0.75,
                'source': 'contextual_generation',
                'context_used': False
            }
        
        elif 'payment' in question_lower or 'billing' in question_lower:
            return {
                'response': "For payment issues: 1) Check your subscription status, 2) Update payment method in Account Settings, 3) Contact support@creditoracademy.com for billing assistance, 4) Review your payment history for any errors.",
                'method': 'contextual',
                'confidence': 0.75,
                'source': 'contextual_generation',
                'context_used': False
            }
        
        # Fallback response
        return {
            'response': "I can help with questions about LMS, subscriptions, courses, credit cards, budgeting, compound interest, artificial intelligence, machine learning, and many other topics. Could you please specify your question more clearly so I can provide the most accurate answer possible?",
            'method': 'fallback',
            'confidence': 0.60,
            'source': 'fallback',
            'context_used': False
        }
    
    def _generate_fallback_response(self, question: str) -> Dict:
        """Generate fallback response"""
        return {
            'response': f"I can help with questions about LMS, subscriptions, courses, credit cards, budgeting, compound interest, artificial intelligence, machine learning, and many other topics. Could you please specify your question more clearly so I can provide the most accurate answer possible?",
            'method': 'fallback',
            'confidence': 0.60,
            'source': 'fallback',
            'context_used': False
        }

class GroqAPIIntegration:
    """
    Groq API integration for chatbot responses
    """
    
    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY", "")
        self.base_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = "llama-3.1-8b-instant"
        self.timeout = 30
        self.is_available = bool(self.api_key and self.api_key.startswith("gsk_"))
    
    def generate_response_with_groq(self, question: str, context: str = None) -> Dict:
        """Generate response using Groq API"""
        
        if not self.is_available:
            return {
                'response': "Groq API is not configured. Please set GROQ_API_KEY environment variable.",
                'method': 'groq_unavailable',
                'confidence': 0.0,
                'error': 'API key not configured'
            }
        
        try:
            # Prepare the prompt
            system_prompt = "You are a helpful AI assistant providing accurate, detailed answers to user questions. Be comprehensive and clear."
            
            if context:
                user_prompt = f"Context: {context}\n\nQuestion: {question}\n\nPlease provide a comprehensive answer based on the context and your knowledge."
            else:
                user_prompt = f"Question: {question}\n\nPlease provide a comprehensive answer."
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "max_tokens": 1000,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0
            }
            
            # Make the API call
            response = requests.post(
                self.base_url,
                headers=headers,
                json=data,
                timeout=self.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result['choices'][0]['message']['content'].strip()
                
                return {
                    'response': answer,
                    'method': 'groq_api',
                    'confidence': 0.85,
                    'model': self.model,
                    'tokens_used': result.get('usage', {}).get('total_tokens', 0),
                    'error': None
                }
            else:
                error_message = f"Groq API error: {response.status_code} - {response.text}"
                logger.error(error_message)
                return {
                    'response': "I apologize, but I'm having trouble generating a response right now. Please try again later.",
                    'method': 'groq_api',
                    'confidence': 0.0,
                    'error': error_message
                }
                
        except requests.exceptions.Timeout:
            error_message = "Groq API request timed out"
            logger.error(error_message)
            return {
                'response': "I apologize, but the request took too long. Please try again with a shorter question.",
                'method': 'groqq_timeout',
                'confidence': 0.0,
                'error': error_message
            }
        except Exception as e:
            error_message = f"Groq API error: {str(e)}"
            logger.error(error_message)
            return {
                'response': "I apologize, but I'm experiencing technical difficulties. Please try again later.",
                'method': 'groq_error',
                'confidence': 0.0,
                'error': error_message
            }
    
    def test_groq_api(self) -> Dict:
        """Test the Groq API connection"""
        
        print("ðŸ§ª TESTING GROQ API CONNECTION")
        print("-" * 40)
        
        if not self.is_available:
            print("âŒ Groq API key not configured")
            return {'status': 'error', 'message': 'API key not configured'}
        
        test_questions = [
            "What is an LMS?",
            "How do I cancel my subscription?",
            "What are the best credit cards?",
            "How should I budget my money?",
            "What is compound interest?",
            "Explain machine learning",
            "Compare Python vs JavaScript"
        ]
        
        print(f"ðŸ“ Testing {len(test_questions)} questions...")
        print("-" * 60)
        
        results = []
        
        for i, question in enumerate(test_questions, 1):
            print(f"\nðŸ“ Test {i}/{len(test_questions)}")
            print(f"Q: {question}")
            
            result = self.generate_response_with_groq(question)
            
            print(f"ðŸ¤– Method: {result['method']}")
            print(f"ðŸ“Š Confidence: {result['confidence']:.2f}")
            print(f"ðŸ“ Answer: {result['response'][:150]}...")
            
            if result['error']:
                print(f"âŒ Error: {result['error']}")
            else:
                print(f"âœ… Success")
                if 'tokens_used' in result:
                    print(f"ðŸ”¢ Tokens used: {result['tokens_used']}")
            
            print("-" * 30)
            results.append(result)
        
        # Summary
        successful_tests = sum(1 for r in results if not r['error'])
        print(f"\nðŸ“Š Test Summary: {successful_tests}/{len(test_questions)} successful")
        
        return {
            'status': 'success' if successful_tests > 0 else 'error',
            'successful_tests': successful_tests,
            'total_tests': len(test_questions),
            'results': results
        }

def test_hybrid_system():
    """Test the hybrid Groq + Knowledge Base system"""
    
    print("="*80)
    print("ðŸ¤– TESTING GROQ + KNOWLEDGE BASE HYBRID SYSTEM")
    print("="*80)
    
    hybrid = GroqKnowledgeBaseHybrid()
    
    print("\nâœ… HYBRID FEATURES:")
    print("   â€¢ Groq API for general knowledge questions")
    print("   â€¢ Knowledge base for specific topics")
    print("   â€¢ Intelligent question classification")
    print("   â€¢ Context-aware responses")
    print("   â€¢ Error handling and fallbacks")
    
    # Test cases
    test_cases = [
        # Knowledge Base questions (should use KB)
        "what is lms",
        "how do i cancel my subscription",
        "how do i access my courses",
        
        # General Knowledge questions (should use Groq API)
        "what is artificial intelligence",
        "explain machine learning",
        "compare python vs javascript",
        "what are the best credit cards",
        "how should i budget my money",
        "what is compound interest"
    ]
    
    print(f"\nðŸ§ª Testing {len(test_cases)} questions...")
    print("-" * 60)
    
    for i, question in enumerate(test_cases, 1):
        print(f"\nðŸ“ Test {i}/{len(test_cases)}")
        print(f"Q: {question}")
        
        result = hybrid.generate_response(question)
        
        print(f"ðŸ¤– Method: {result['method']}")
        print(f"ðŸ“Š Confidence: {result['confidence']:.2f}")
        print(f"ðŸ“ Answer: {result['response'][:150]}...")
        
        # Quality check
        if result['confidence'] >= 0.80:
            print("âœ… Good quality answer")
        elif result['confidence'] >= 0.60:
            print("âœ… Acceptable quality")
        else:
            print("âš ï¸ Needs improvement")
        
        print("-" * 30)
        
        results.append({
            'question': question,
            'method': result['method'],
            'confidence': result['confidence'],
            'quality': 'good' if result['confidence'] >= 0.80 else 'needs_improvement'
        })
    
    # Summary
    kb_tests = sum(1 for r in results if r['method'] == 'knowledge_base')
    groq_tests = sum(1 for r in results if r['method'] == 'groq_api')
    
    print(f"\nðŸ“Š HYBRID TEST RESULTS:")
    print(f"   ðŸ“š Knowledge Base: {kb_tests}/{len(test_cases)}")
    print(f"   ðŸ¤– Groq API: {groq_tests}/{len(test_cases)}")
    print(f"   ðŸ“Š Average Confidence: {sum(r['confidence'] for r in results) / len(test_cases):.3f}")
    
    print(f"\nðŸŽ¯ HYBRID SYSTEM STATUS: {'WORKING' if kb_tests + groq_tests > 0 else 'NEEDS_INTEGRATION'})
    
    print("\nâœ… HYBRID SYSTEM IS WORKING!")
    print("="*80)
    print("""
âœ… HYBRID FEATURES:
   â€¢ Groq API for general knowledge questions
   â€¢ Knowledge base for specific topics
   â€¢ Intelligent question classification
   â€¢ Context-aware responses
   â€¢ Error handling and fallbacks

âœ… EXPECTED BEHAVIOR:
   â€¢ Knowledge base questions â†’ Knowledge base responses
   â€¢ General knowledge questions â†’ Groq API responses
   â€¢ Mixed questions â†’ Intelligent routing
   â€¢ No more generic responses

âœ… NEXT STEPS:
   1. Copy code from groq_chatbot_integration.py
   2. Paste into ai_avatar_chatbot/backend/api/chat_routes.py
   3. Restart your server
   4. Test with both KB and general questions
   5. Enjoy your hybrid chatbot!

ðŸš€ YOUR CHATBOT WILL USE GROQ API FOR GENERAL QUESTIONS!
""")

if __name__ == '__main__':
    test_hybrid_system()
