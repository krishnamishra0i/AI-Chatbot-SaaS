<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Speech-to-Speech Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .mic-btn {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            font-size: 40px;
            cursor: pointer;
            margin: 20px auto;
            display: block;
            transition: all 0.3s;
        }
        .mic-btn:hover {
            transform: scale(1.1);
        }
        .mic-btn.recording {
            background: linear-gradient(135deg, #ef4444, #dc2626);
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        .status {
            text-align: center;
            padding: 15px;
            margin: 10px 0;
            border-radius: 8px;
            font-weight: bold;
        }
        .status.listening { background: #fef3c7; color: #92400e; }
        .status.processing { background: #dbeafe; color: #1e40af; }
        .status.speaking { background: #d1fae5; color: #065f46; }
        .transcript {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            min-height: 50px;
        }
        .response {
            background: #e0f2fe;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            min-height: 50px;
        }
        .error {
            background: #fee2e2;
            color: #991b1b;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Real-time Speech-to-Speech Test</h1>
        <p>Press and hold the microphone button to speak, then release to get an instant voice answer.</p>
        
        <button id="micBtn" class="mic-btn">üéôÔ∏è</button>
        
        <div id="status" class="status">Ready</div>
        
        <div>
            <h3>You said:</h3>
            <div id="transcript" class="transcript">...</div>
        </div>
        
        <div>
            <h3>AI Response:</h3>
            <div id="response" class="response">...</div>
        </div>
        
        <div id="error" class="error" style="display: none;"></div>
        
        <div style="margin-top: 30px; padding: 15px; background: #f0f9ff; border-radius: 8px;">
            <h3>How it works:</h3>
            <ol>
                <li>Press and hold üéôÔ∏è button</li>
                <li>Speak your question</li>
                <li>Release the button</li>
                <li>Get instant voice answer</li>
            </ol>
        </div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const response = document.getElementById('response');
        const error = document.getElementById('error');
        
        // Start recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await processAudio(audioBlob);
                };
                
                mediaRecorder.start();
                isRecording = true;
                micBtn.classList.add('recording');
                status.textContent = 'üé§ Listening... Speak now';
                status.className = 'status listening';
                error.style.display = 'none';
                
            } catch (err) {
                showError('Microphone access denied: ' + err.message);
            }
        }
        
        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                micBtn.classList.remove('recording');
                status.textContent = 'üß† Processing...';
                status.className = 'status processing';
            }
        }
        
        // Process audio and get response
        async function processAudio(audioBlob) {
            try {
                // Convert to base64
                const reader = new FileReader();
                reader.readAsDataURL(audioBlob);
                reader.onloadend = async () => {
                    const base64Audio = reader.result.split(',')[1];
                    
                    // Send to backend for transcription and response
                    const formData = new FormData();
                    formData.append('audio_file', audioBlob, 'audio.wav');
                    
                    status.textContent = 'üß† Processing...';
                    
                    // Get transcript
                    const sttResponse = await fetch('http://localhost:8000/api/stt/transcribe', {
                        method: 'POST',
                        body: formData
                    });
                    
                    const sttData = await sttResponse.json();
                    const userText = sttData.text || '';
                    
                    transcript.textContent = userText || 'Could not transcribe';
                    
                    if (!userText) {
                        showError('Could not understand what you said');
                        status.textContent = 'Ready';
                        status.className = 'status';
                        return;
                    }
                    
                    // Get AI response
                    const chatResponse = await fetch('http://localhost:8000/api/chat', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ message: userText })
                    });
                    
                    const chatData = await chatResponse.json();
                    const aiText = chatData.response || '';
                    
                    response.textContent = aiText || 'No response';
                    
                    // Convert to speech
                    if (aiText) {
                        status.textContent = 'üîä Speaking...';
                        status.className = 'status speaking';
                        
                        const ttsResponse = await fetch('http://localhost:8000/api/tts/synthesize-audio', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ 
                                text: aiText,
                                voice: 'en-US-GuyNeural'
                            })
                        });
                        
                        if (ttsResponse.ok) {
                            const audioBlob = await ttsResponse.blob();
                            const audioUrl = URL.createObjectURL(audioBlob);
                            const audio = new Audio(audioUrl);
                            
                            audio.onended = () => {
                                status.textContent = 'Ready';
                                status.className = 'status';
                                URL.revokeObjectURL(audioUrl);
                            };
                            
                            audio.onerror = () => {
                                showError('Audio playback failed');
                                status.textContent = 'Ready';
                                status.className = 'status';
                            };
                            
                            await audio.play();
                        } else {
                            // Fallback to browser TTS
                            const utterance = new SpeechSynthesisUtterance(aiText);
                            utterance.onend = () => {
                                status.textContent = 'Ready';
                                status.className = 'status';
                            };
                            speechSynthesis.speak(utterance);
                        }
                    } else {
                        status.textContent = 'Ready';
                        status.className = 'status';
                    }
                };
                
            } catch (err) {
                showError('Processing error: ' + err.message);
                status.textContent = 'Ready';
                status.className = 'status';
            }
        }
        
        function showError(message) {
            error.textContent = message;
            error.style.display = 'block';
            setTimeout(() => {
                error.style.display = 'none';
            }, 5000);
        }
        
        // Microphone button events
        micBtn.addEventListener('mousedown', startRecording);
        micBtn.addEventListener('mouseup', stopRecording);
        micBtn.addEventListener('mouseleave', stopRecording);
        
        // Touch events for mobile
        micBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording();
        });
        micBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopRecording();
        });
    </script>
</body>
</html>
