<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Complete Speech-to-Speech System</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            padding: 40px;
            max-width: 600px;
            width: 100%;
        }
        
        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 16px;
        }
        
        .mic-container {
            text-align: center;
            margin: 30px 0;
        }
        
        .mic-btn {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            font-size: 60px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            position: relative;
            overflow: hidden;
        }
        
        .mic-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
        }
        
        .mic-btn.recording {
            background: linear-gradient(135deg, #ef4444, #dc2626);
            animation: recordPulse 1.5s ease-in-out infinite;
        }
        
        @keyframes recordPulse {
            0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7); }
            70% { box-shadow: 0 0 0 30px rgba(239, 68, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }
        }
        
        .status {
            text-align: center;
            padding: 20px;
            margin: 20px 0;
            border-radius: 15px;
            font-weight: 600;
            font-size: 18px;
            transition: all 0.3s ease;
        }
        
        .status.ready { 
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
        }
        
        .status.listening { 
            background: linear-gradient(135deg, #f59e0b, #d97706);
            color: white;
        }
        
        .status.processing { 
            background: linear-gradient(135deg, #3b82f6, #2563eb);
            color: white;
        }
        
        .status.speaking { 
            background: linear-gradient(135deg, #8b5cf6, #7c3aed);
            color: white;
        }
        
        .transcript-box, .response-box {
            background: #f8fafc;
            border: 2px solid #e2e8f0;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            min-height: 80px;
            transition: all 0.3s ease;
        }
        
        .transcript-box {
            border-left: 5px solid #10b981;
        }
        
        .response-box {
            border-left: 5px solid #3b82f6;
            background: #eff6ff;
        }
        
        .box-label {
            font-weight: 600;
            color: #374151;
            margin-bottom: 10px;
            font-size: 14px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .box-content {
            color: #1f2937;
            font-size: 16px;
            line-height: 1.5;
        }
        
        .error {
            background: linear-gradient(135deg, #fee2e2, #fecaca);
            color: #991b1b;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            display: none;
            border: 1px solid #fca5a5;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .test-btn {
            background: linear-gradient(135deg, #6366f1, #4f46e5);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 4px 6px rgba(99, 102, 241, 0.3);
        }
        
        .test-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 12px rgba(99, 102, 241, 0.4);
        }
        
        .test-btn:active {
            transform: translateY(0);
        }
        
        .test-results {
            margin-top: 20px;
            padding: 15px;
            background: #f1f5f9;
            border-radius: 10px;
            min-height: 50px;
        }
        
        .pulse {
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .success {
            background: linear-gradient(135deg, #10b981, #059669);
            color: white;
            padding: 10px;
            border-radius: 5px;
            margin: 5px 0;
        }
        
        .failure {
            background: linear-gradient(135deg, #ef4444, #dc2626);
            color: white;
            padding: 10px;
            border-radius: 5px;
            margin: 5px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Complete Speech-to-Speech System</h1>
        <p class="subtitle">Press and hold the microphone to speak, release to get instant AI voice response</p>
        
        <div class="mic-container">
            <button id="micBtn" class="mic-btn">üéôÔ∏è</button>
        </div>
        
        <div id="status" class="status ready">‚úÖ Ready - Press and hold microphone to speak</div>
        
        <div class="transcript-box">
            <div class="box-label">üó£Ô∏è You Said:</div>
            <div id="transcript" class="box-content">...</div>
        </div>
        
        <div class="response-box">
            <div class="box-label">ü§ñ AI Response:</div>
            <div id="response" class="box-content">...</div>
        </div>
        
        <div id="error" class="error"></div>
        
        <div class="controls">
            <button class="test-btn" onclick="testBackend()">üîß Test Backend</button>
            <button class="test-btn" onclick="testMicrophone()">üé§ Test Mic</button>
            <button class="test-btn" onclick="testFullFlow()">üöÄ Test Full Flow</button>
        </div>
        
        <div id="testResults" class="test-results"></div>
    </div>

    <script>
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let audioContext = null;
        let analyser = null;
        
        const micBtn = document.getElementById('micBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const response = document.getElementById('response');
        const error = document.getElementById('error');
        const testResults = document.getElementById('testResults');
        
        // Initialize audio context
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
            }
        }
        
        // Update status with animation
        function updateStatus(text, className) {
            status.className = 'status ' + className;
            status.textContent = text;
            status.classList.add('pulse');
            setTimeout(() => status.classList.remove('pulse'), 1000);
        }
        
        // Show error
        function showError(message) {
            error.textContent = '‚ùå ' + message;
            error.style.display = 'block';
            setTimeout(() => {
                error.style.display = 'none';
            }, 8000);
        }
        
        // Show test result
        function showTestResult(message, isSuccess = true) {
            const div = document.createElement('div');
            div.className = isSuccess ? 'success' : 'failure';
            div.textContent = (isSuccess ? '‚úÖ ' : '‚ùå ') + message;
            testResults.appendChild(div);
            testResults.scrollTop = testResults.scrollHeight;
        }
        
        // Test backend connection
        async function testBackend() {
            testResults.innerHTML = '';
            showTestResult('Testing backend connection...');
            
            try {
                const response = await fetch('http://localhost:8000/api/enhanced-status');
                const data = await response.json();
                
                if (data.components) {
                    showTestResult('Backend connected successfully!');
                    showTestResult(`LLM: ${data.components.llm.available ? 'Working' : 'Not working'}`, data.components.llm.available);
                    showTestResult(`TTS: ${data.components.tts.available ? 'Working' : 'Not working'}`, data.components.tts.available);
                    showTestResult(`STT: ${data.components.stt.available ? 'Working' : 'Not working'}`, data.components.stt.available);
                } else {
                    showTestResult('Backend response format unexpected', false);
                }
            } catch (err) {
                showTestResult('Backend connection failed: ' + err.message, false);
            }
        }
        
        // Test microphone
        async function testMicrophone() {
            testResults.innerHTML = '';
            showTestResult('Testing microphone access...');
            
            try {
                initAudioContext();
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Test audio levels
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                
                function checkAudioLevel() {
                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    
                    if (average > 10) {
                        showTestResult('Microphone working - audio detected!');
                        stream.getTracks().forEach(track => track.stop());
                    } else {
                        setTimeout(checkAudioLevel, 100);
                    }
                }
                
                showTestResult('Please make a sound...');
                checkAudioLevel();
                
            } catch (err) {
                showTestResult('Microphone access denied: ' + err.message, false);
            }
        }
        
        // Test full flow
        async function testFullFlow() {
            testResults.innerHTML = '';
            showTestResult('Testing complete speech-to-speech flow...');
            
            try {
                // Test with a sample text
                const testText = "Hello, this is a test of the speech to speech system.";
                
                // Test chat
                const chatResponse = await fetch('http://localhost:8000/api/chat', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: testText })
                });
                
                const chatData = await chatResponse.json();
                showTestResult('Chat API working!');
                
                // Test TTS
                const ttsResponse = await fetch('http://localhost:8000/api/tts/synthesize-audio', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ 
                        text: chatData.response || testText,
                        voice: 'en-US-GuyNeural'
                    })
                });
                
                if (ttsResponse.ok) {
                    const audioBlob = await ttsResponse.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    await audio.play();
                    
                    showTestResult('Full flow working! Audio should be playing.');
                } else {
                    throw new Error('TTS failed');
                }
                
            } catch (err) {
                showTestResult('Full flow test failed: ' + err.message, false);
            }
        }
        
        // Start recording with enhanced audio capture
        async function startRecording() {
            try {
                initAudioContext();
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    } 
                });
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await processAudio(audioBlob);
                };
                
                mediaRecorder.start(100); // Collect data every 100ms
                isRecording = true;
                micBtn.classList.add('recording');
                updateStatus('üé§ Listening... Speak clearly into your microphone', 'listening');
                error.style.display = 'none';
                
            } catch (err) {
                showError('Microphone error: ' + err.message);
                updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
            }
        }
        
        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;
                micBtn.classList.remove('recording');
                updateStatus('üß† Processing your speech...', 'processing');
            }
        }
        
        // Process audio with better error handling
        async function processAudio(audioBlob) {
            try {
                // Convert webm to wav if needed
                let processedBlob = audioBlob;
                
                // Step 1: Transcribe audio
                const formData = new FormData();
                formData.append('audio_file', processedBlob, 'recording.webm');
                
                updateStatus('üß† Transcribing your speech...', 'processing');
                
                const sttResponse = await fetch('http://localhost:8000/api/stt/transcribe', {
                    method: 'POST',
                    body: formData
                });
                
                if (!sttResponse.ok) {
                    throw new Error('Speech recognition failed');
                }
                
                const sttData = await sttResponse.json();
                const userText = sttData.text || '';
                
                transcript.textContent = userText || '(Could not understand - please speak clearly)';
                
                if (!userText || userText.trim().length < 2) {
                    showError('Could not understand what you said. Please speak clearly and try again.');
                    updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
                    return;
                }
                
                // Step 2: Get AI response
                updateStatus('ü§ñ Generating AI response...', 'processing');
                
                const chatResponse = await fetch('http://localhost:8000/api/chat', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ message: userText })
                });
                
                if (!chatResponse.ok) {
                    throw new Error('AI response generation failed');
                }
                
                const chatData = await chatResponse.json();
                const aiText = chatData.response || '';
                
                response.textContent = aiText || '(No response received)';
                
                // Step 3: Convert to speech
                if (aiText) {
                    updateStatus('üîä Generating voice response...', 'speaking');
                    
                    try {
                        const ttsResponse = await fetch('http://localhost:8000/api/tts/synthesize-audio', {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ 
                                text: aiText,
                                voice: 'en-US-GuyNeural'
                            })
                        });
                        
                        if (ttsResponse.ok) {
                            const audioBlob = await ttsResponse.blob();
                            const audioUrl = URL.createObjectURL(audioBlob);
                            const audio = new Audio(audioUrl);
                            
                            audio.onended = () => {
                                updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
                                URL.revokeObjectURL(audioUrl);
                            };
                            
                            audio.onerror = () => {
                                showError('Audio playback failed, but you can read the response above');
                                updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
                            };
                            
                            await audio.play();
                        } else {
                            throw new Error('TTS generation failed');
                        }
                    } catch (ttsErr) {
                        // Fallback to browser speech
                        const utterance = new SpeechSynthesisUtterance(aiText);
                        utterance.rate = 1.0;
                        utterance.pitch = 1.0;
                        utterance.volume = 1.0;
                        utterance.onend = () => {
                            updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
                        };
                        speechSynthesis.speak(utterance);
                    }
                } else {
                    updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
                }
                
            } catch (err) {
                showError('Processing error: ' + err.message);
                updateStatus('‚úÖ Ready - Press and hold microphone to speak', 'ready');
            }
        }
        
        // Microphone button events
        micBtn.addEventListener('mousedown', startRecording);
        micBtn.addEventListener('mouseup', stopRecording);
        micBtn.addEventListener('mouseleave', stopRecording);
        
        // Touch events for mobile
        micBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startRecording();
        });
        micBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopRecording();
        });
        
        // Prevent context menu on long press
        micBtn.addEventListener('contextmenu', (e) => {
            e.preventDefault();
        });
        
        // Auto-test on load
        window.addEventListener('load', () => {
            setTimeout(testBackend, 1000);
        });
    </script>
</body>
</html>
